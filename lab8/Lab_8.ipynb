{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50c37a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/11/23 07:00:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# since everyone will be using cluster at the same time\n",
    "# let's make sure that everyone has resource. that is why \n",
    "# the configuration uses dynamic resource allocation and\n",
    "# maximum 1 executor \n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\")\\\n",
    "    .config(\"spark.dynamicAllocation.shuffleTracking.enabled\", \"true\")\\\n",
    "    .config(\"spark.dynamicAllocation.maxExecutors\", \"1\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19cfbe25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "songs_df = spark.read.load(\"./train_triplets.txt\",\n",
    "                     format=\"csv\", sep=\"\\t\", inferSchema=\"true\", \n",
    "                     header=\"false\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d7bb9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42e9d870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user: string (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- play_count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs_df.createOrReplaceTempView(\"songs\")\n",
    "songs_df = songs_df.withColumnRenamed(\"_c0\", \"user\")\\\n",
    "                   .withColumnRenamed(\"_c1\", \"song\")\\\n",
    "                   .withColumnRenamed(\"_c2\", \"play_count\")\n",
    "songs_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "540089f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "played_more_than_10_times = spark.sql(\"select song from songs where play_count > 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79673bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2043582"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "played_more_than_10_times.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14e4692e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "username = \"b80344d063b5ccb3212f76538f3d9e43d87dca9e\"\n",
    "played_by_user = spark.sql(f\"select song from songs where user=\\\"{username}\\\"\")\n",
    "played_by_user.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87e731d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(user='b80344d063b5ccb3212f76538f3d9e43d87dca9e')\n"
     ]
    }
   ],
   "source": [
    "first_ten_entries = spark.sql(f\"select user from songs limit 10\")\n",
    "print(first_ten_entries.collect()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f2de44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "username = \"b80344d063b5ccb3212f76538f3d9e43d87dca9e\"\n",
    "played_by_user_more_than_10_times = spark.sql(f\"select song from songs where user=\\\"{username}\\\" and play_count > 10\")\n",
    "played_by_user_more_than_10_times.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04745402",
   "metadata": {},
   "source": [
    "## Yelp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "751a8dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/23 07:02:03 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "business = spark.read.json(\"./yelp-dataset/yelp_academic_dataset_business.json\")\n",
    "reviews = spark.read.json(\"./yelp-dataset/yelp_academic_dataset_review.json\")\n",
    "users = spark.read.json(\"./yelp-dataset/yelp_academic_dataset_user.json\")\n",
    "business.createOrReplaceTempView(\"business\")\n",
    "reviews.createOrReplaceTempView(\"reviews\")\n",
    "users.createOrReplaceTempView(\"users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5eb7d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:============================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|state|count|\n",
      "+-----+-----+\n",
      "|   AZ|56686|\n",
      "|   NV|36312|\n",
      "|   ON|33412|\n",
      "|   NC|14720|\n",
      "|   OH|14697|\n",
      "|   PA|11216|\n",
      "|   QC| 9219|\n",
      "|   AB| 8012|\n",
      "|   WI| 5154|\n",
      "|   IL| 1932|\n",
      "|   SC| 1162|\n",
      "|   NY|   22|\n",
      "|   CA|   19|\n",
      "|   TX|    6|\n",
      "|   FL|    4|\n",
      "|  XGM|    4|\n",
      "|   AL|    3|\n",
      "|   WA|    3|\n",
      "|   CT|    3|\n",
      "|   VA|    2|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select state, count(state) as count from business group by state order by count(state) desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3429c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|count(DISTINCT category)|\n",
      "+------------------------+\n",
      "|                    2468|\n",
      "+------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select count(distinct(*)) from (\n",
    "    select explode(split(categories, \\\",\\s*\\\")) as category from business\n",
    ")\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b24b5aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:===========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------------+\n",
      "|         category|count(category)|\n",
      "+-----------------+---------------+\n",
      "|      Restaurants|           2815|\n",
      "|         Shopping|           2416|\n",
      "|    Home Services|           2302|\n",
      "|             Food|           1672|\n",
      "| Health & Medical|           1577|\n",
      "|   Local Services|           1444|\n",
      "|      Restaurants|           1184|\n",
      "|       Automotive|           1164|\n",
      "|    Beauty & Spas|           1115|\n",
      "|    Home Services|            843|\n",
      "+-----------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select category, count(category) from \n",
    "    (\n",
    "        select explode(split(categories, \\\",\\s*\\\")) as category \n",
    "        from business where city=\\\"Phoenix\\\"\n",
    "    )\n",
    "group by category order by count(category) desc limit 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00b15c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|          categories|\n",
      "+--------------------+\n",
      "|Specialty Food, R...|\n",
      "|Chinese, Dim Sum,...|\n",
      "|Chinese, Restaurants|\n",
      "|Restaurants, Chinese|\n",
      "|Chinese, Restaurants|\n",
      "|Chinese, Restaurants|\n",
      "|Dim Sum, Chinese,...|\n",
      "|Chinese, Restaurants|\n",
      "|Local Flavor, Chi...|\n",
      "|Restaurants, Hawa...|\n",
      "|Sushi Bars, Buffe...|\n",
      "|Chinese, Restaura...|\n",
      "|Hakka, Indian, As...|\n",
      "|Buffets, Chinese,...|\n",
      "|Seafood, Chinese,...|\n",
      "|Chinese, Restaurants|\n",
      "|Do-It-Yourself Fo...|\n",
      "|Chinese, Restaurants|\n",
      "|Chinese, Seafood,...|\n",
      "|Restaurants, Fast...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "with business_category (select *, explode(split(categories, \\\",\\s*\\\")) as category from business)\n",
    "select categories from business where categories like '%Restaurant%' and categories like '%Chinese%'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "077325a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:==================================================>     (17 + 2) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|friend_count|\n",
      "+------------+\n",
      "|        4166|\n",
      "+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select \n",
    "    count(*) as friend_count \n",
    "from \n",
    "    users \n",
    "where \n",
    "    size(split(friends, \\\",\\s*\\\")) > 1000\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6788bca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 58:======================================================> (39 + 1) / 40]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------------+\n",
      "|         business_id|            rating|            rating|\n",
      "+--------------------+------------------+------------------+\n",
      "|WU6mFeLp8PASoA9jd...|               4.0|               2.2|\n",
      "|45rWYQPlQ4x5cFU0u...|              4.25|               3.0|\n",
      "|MGsV9nuGOr9fxtzJP...|3.4285714285714284|               3.0|\n",
      "|tWjfgVtTD5n01Cq9d...|3.6666666666666665|3.6451612903225805|\n",
      "|JO5_Frcbp9J732VNn...|               2.2|1.2857142857142858|\n",
      "|btQ4Rc7am0KWNIcgt...|               4.5| 2.857142857142857|\n",
      "|FXdAittxUsIR-SWPu...|3.1666666666666665|2.3333333333333335|\n",
      "|Ky67Nk2SLRRaHSYuz...|               5.0|1.3333333333333333|\n",
      "|AiEKjZPj2J3MpnBZk...|               4.0|               3.5|\n",
      "|Ve_RgUoXVEeNnpvmS...|               4.0|               3.5|\n",
      "|p-8PgN7S4VUUXH6y5...|3.3333333333333335|2.2222222222222223|\n",
      "|kZ36LGvnwetEq-seq...| 3.769230769230769|3.6666666666666665|\n",
      "|px2ZZOPzA8-xG_VhE...| 2.533333333333333|1.6964285714285714|\n",
      "|UoPOED2pSAQjf4Gz4...|              3.75|1.3333333333333333|\n",
      "|FJoXrkLaLh76MgHXK...|               4.0| 3.933333333333333|\n",
      "|ROyteoFTxe7i3PZCE...|               5.0|               4.5|\n",
      "|VUknuJV7f9DoqiYds...|3.4705882352941178|3.2941176470588234|\n",
      "|426RL7G7oTyu-f8jF...| 3.611111111111111|               2.8|\n",
      "|1EbdmUMbrS12Dougf...|               3.0|               2.8|\n",
      "|0L3CAgRf8wuH5MjNw...| 4.111111111111111|3.5555555555555554|\n",
      "+--------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "with business_ratings as (\n",
    "    select \n",
    "        business_id, year(to_date(date)) as year, avg(stars) as rating \n",
    "    from \n",
    "        reviews group by business_id, year(to_date(date))\n",
    "),\n",
    "business_2014 as (\n",
    "    select \n",
    "        business_id, rating \n",
    "    from \n",
    "        business_ratings \n",
    "    where \n",
    "        year=2014\n",
    "),\n",
    "business_2017 as (\n",
    "    select \n",
    "        business_id, rating \n",
    "    from \n",
    "        business_ratings where year=2017\n",
    ")\n",
    "select \n",
    "    business_2014.business_id, business_2014.rating, business_2017.rating \n",
    "from \n",
    "    business_2014 \n",
    "inner join \n",
    "    business_2017 \n",
    "on \n",
    "    business_2014.business_id=business_2017.business_id \n",
    "where \n",
    "    business_2017.rating < business_2014.rating \n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1aa057",
   "metadata": {},
   "source": [
    "## Last query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5bde7b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:=====================================================>  (18 + 1) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              friend|\n",
      "+--------------------+\n",
      "| -00Egx3njsVJcffb...|\n",
      "| -04Jyy-WuPWpllQW...|\n",
      "| -0LF0KoZLL8OiDU4...|\n",
      "| -0oIA-m3Wc11-jc0...|\n",
      "| -0zUpn_6kTWXHWzB...|\n",
      "| -1A3SCg5pLrHw348...|\n",
      "| -1vHfy-zKYr0BEyv...|\n",
      "| -2_quDPr8JZezokU...|\n",
      "| -2ng4a1kUcsyuqa-...|\n",
      "| -2vxL7OSMUAuQl2c...|\n",
      "| -42EDLVIoALtrtBM...|\n",
      "| -50r1_gkfzZKKeTZ...|\n",
      "| -5LnQ_ArAn0o_RCc...|\n",
      "| -6DoXmdXEy_P5N-Q...|\n",
      "| -6uXqbL1TvTHLyfs...|\n",
      "| -7jaf-ejcyTX_JTD...|\n",
      "| -8Rj4t1fFxpWNCs9...|\n",
      "| -9Eg_UzsR8YiV3UY...|\n",
      "| -9Ji22rM656HohYE...|\n",
      "| -9nBr-QuSuHVHT6l...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# business.printSchema()\n",
    "# reviews.printSchema()\n",
    "# users.printSchema()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "with last_reviews(\n",
    "    with chinese_restaurant(\n",
    "    select * from business where categories like '%Chinese%' and categories like '%Restaurant%'\n",
    "    )\n",
    "    select user_id, max(to_date(date)) \n",
    "    from reviews join chinese_restaurant on reviews.business_id=chinese_restaurant.business_id\n",
    "    group by user_id\n",
    ")\n",
    "\n",
    "select distinct(explode(split(friends, \\\",\\s*\\\"))) as friend\n",
    "from last_reviews join users on last_reviews.user_id=users.user_id\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49266ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d81b526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
